{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangExtract Integration ‚Äì All-in-One Demo\n",
    "\n",
    "This notebook demonstrates an end-to-end extraction workflow optimized for PDFs and free-form text:\n",
    "\n",
    "- Load env and route via OpenRouter (from `.env`)\n",
    "- Use project venv (prints Python executable)\n",
    "- Upload/select a PDF or paste text; parse via `src/processors/pdf_parser.py`\n",
    "- Edit the LangExtract system prompt and few-shot examples\n",
    "- Run extraction with `src/langextract_integration`\n",
    "- Review raw results, normalized table, and LangExtract visualizations\n",
    "- Save outputs (JSON, JSONL, HTML, CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded .env from: /Users/Mitya/Desktop/working/biomedicalmedical_text_agent/.env\n",
      "üß™ Python: /Users/Mitya/Desktop/working/biomedicalmedical_text_agent/venv/bin/python\n",
      "ü™∫ VIRTUAL_ENV: /Users/Mitya/Desktop/working/biomedicalmedical_text_agent/venv\n",
      "üîë OpenRouter API key detected and configured\n",
      "‚úÖ nbformat available\n"
     ]
    }
   ],
   "source": [
    "# Environment: load .env, configure OpenRouter, show venv\n",
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from repository root\n",
    "repo_root = os.path.abspath(os.path.join('..'))\n",
    "env_file = os.path.join(repo_root, '.env')\n",
    "if os.path.exists(env_file):\n",
    "    load_dotenv(env_file)\n",
    "    print(\"‚úÖ Loaded .env from:\", env_file)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è .env not found at:\", env_file)\n",
    "\n",
    "# Show interpreter and venv\n",
    "print(\"üß™ Python:\", sys.executable)\n",
    "print(\"ü™∫ VIRTUAL_ENV:\", os.environ.get('VIRTUAL_ENV', 'not set'))\n",
    "\n",
    "# Configure OpenRouter\n",
    "OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\n",
    "if OPENROUTER_API_KEY:\n",
    "    os.environ['OPENAI_BASE_URL'] = 'https://openrouter.ai/api/v1'\n",
    "    os.environ['OPENAI_API_KEY'] = OPENROUTER_API_KEY\n",
    "    os.environ['OPENROUTER_API_KEY'] = OPENROUTER_API_KEY\n",
    "    print(\"üîë OpenRouter API key detected and configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è OPENROUTER_API_KEY not set; cloud extraction will fail\")\n",
    "\n",
    "# Ensure nbformat for Plotly inline rendering\n",
    "try:\n",
    "    import nbformat  # noqa: F401\n",
    "    print(\"‚úÖ nbformat available\")\n",
    "except Exception:\n",
    "    import subprocess\n",
    "    print(\"‚¨áÔ∏è Installing nbformat for inline rendering...\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'nbformat>=4.2.0'])\n",
    "    import nbformat\n",
    "    print(\"‚úÖ nbformat installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports ready\n"
     ]
    }
   ],
   "source": [
    "# Imports and project modules\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Ensure src on path\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "\n",
    "# LangExtract integration\n",
    "from langextract_integration import (\n",
    "    LangExtractEngine,\n",
    "    BiomedicExtractionClasses,\n",
    "    BiomedicNormalizer,\n",
    "    ExtractionVisualizer,\n",
    ")\n",
    "\n",
    "# Processors\n",
    "from processors.pdf_parser import PDFParser\n",
    "\n",
    "print(\"‚úÖ Imports ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Model: gpt-4o-mini\n",
      "üñ•Ô∏è Local model enabled: False\n",
      "üåê Local URL: http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "# Config controls\n",
    "MODEL_ID = os.getenv('LANGEXTRACT_MODEL_ID', 'gpt-4o-mini')\n",
    "USE_LOCAL_MODEL = os.getenv('USE_LOCAL_MODEL', 'false').lower() in ('1','true','yes')\n",
    "LOCAL_MODEL_URL = os.getenv('LOCAL_MODEL_URL', 'http://localhost:11434')\n",
    "\n",
    "print('ü§ñ Model:', MODEL_ID)\n",
    "print('üñ•Ô∏è Local model enabled:', USE_LOCAL_MODEL)\n",
    "print('üåê Local URL:', LOCAL_MODEL_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë API Key detected in environment\n",
      "‚òÅÔ∏è Using OpenRouter (OpenAI-compatible): gpt-4o-mini\n",
      "ü§ñ Effective model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "# Prefer OpenAI-compatible id to force OpenRouter over Ollama inside LangExtract\n",
    "MODEL_ID = os.getenv(\"LANGEXTRACT_MODEL_ID\", \"gpt-4o-mini\")\n",
    "\n",
    "# Optional local (Ollama) configuration\n",
    "USE_LOCAL_MODEL = os.getenv(\"USE_LOCAL_MODEL\", \"false\").lower() in (\"1\", \"true\", \"yes\")\n",
    "LOCAL_MODEL_ID = os.getenv(\"LOCAL_MODEL_ID\", \"llama3\")\n",
    "LOCAL_MODEL_URL = os.getenv(\"LOCAL_MODEL_URL\", \"http://localhost:11434\")\n",
    "\n",
    "# Load API key from environment for safety (cloud route)\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if not USE_LOCAL_MODEL:\n",
    "    if not OPENROUTER_API_KEY:\n",
    "        print(\"‚ö†Ô∏è OPENROUTER_API_KEY is not set. Set it in your environment to run extraction.\")\n",
    "    else:\n",
    "        print(\"üîë API Key detected in environment\")\n",
    "        # Ensure LangExtract and OpenAI SDKs route via OpenRouter\n",
    "        os.environ[\"OPENAI_BASE_URL\"] = \"https://openrouter.ai/api/v1\"\n",
    "        os.environ[\"OPENAI_API_KEY\"] = OPENROUTER_API_KEY\n",
    "        os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
    "\n",
    "# Echo effective route\n",
    "if USE_LOCAL_MODEL:\n",
    "    print(f\"üñ•Ô∏è Using local model via Ollama: {LOCAL_MODEL_ID} @ {LOCAL_MODEL_URL}\")\n",
    "    EFFECTIVE_MODEL_ID = LOCAL_MODEL_ID\n",
    "else:\n",
    "    print(f\"‚òÅÔ∏è Using OpenRouter (OpenAI-compatible): {MODEL_ID}\")\n",
    "    EFFECTIVE_MODEL_ID = MODEL_ID\n",
    "\n",
    "print(f\"ü§ñ Effective model: {EFFECTIVE_MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input: Upload PDF or Paste Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea5866895544b3f887e0087baf05c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Upload:'), FileUpload(value=(), accept='.pdf', description='Upload'‚Ä¶"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File input helpers\n",
    "from pathlib import Path\n",
    "from ipywidgets import VBox, HBox, Text, Textarea, FileUpload, Button, Label\n",
    "\n",
    "pdf_uploader = FileUpload(accept='.pdf', multiple=False)\n",
    "path_field = Text(value='/Users/Mitya/Desktop/working/biomedicalmedical_text_agent/data/input/PMID32679198.pdf', description='Path:')\n",
    "text_area = Textarea(value='', description='Text:', layout=dict(width='100%', height='200px'))\n",
    "status = Label(value='')\n",
    "\n",
    "load_btn = Button(description='Load PDF', button_style='primary')\n",
    "use_text_btn = Button(description='Use Text', button_style='success')\n",
    "\n",
    "loaded_text = {'text': ''}\n",
    "\n",
    "def on_load_pdf(_):\n",
    "    # Priority 1: file uploader\n",
    "    if pdf_uploader.value:\n",
    "        up_item = next(iter(pdf_uploader.value.values()))\n",
    "        tmp_path = Path('uploaded.pdf')\n",
    "        with open(tmp_path, 'wb') as f:\n",
    "            f.write(up_item['content'])\n",
    "        parser = PDFParser()\n",
    "        res = parser.process(str(tmp_path))\n",
    "        if res.success:\n",
    "            loaded_text['text'] = res.data.content\n",
    "            status.value = f\"‚úÖ Loaded from upload ({len(loaded_text['text'])} chars)\"\n",
    "        else:\n",
    "            status.value = f\"‚ùå PDF parsing failed: {res.error}\"\n",
    "        return\n",
    "    # Priority 2: path field\n",
    "    p = Path(path_field.value)\n",
    "    if p.exists() and p.suffix.lower() == '.pdf':\n",
    "        parser = PDFParser()\n",
    "        res = parser.process(str(p))\n",
    "        if res.success:\n",
    "            loaded_text['text'] = res.data.content\n",
    "            status.value = f\"‚úÖ Loaded from path ({len(loaded_text['text'])} chars)\"\n",
    "        else:\n",
    "            status.value = f\"‚ùå PDF parsing failed: {res.error}\"\n",
    "    else:\n",
    "        status.value = '‚ö†Ô∏è Provide a valid .pdf path or upload a file'\n",
    "\n",
    "def on_use_text(_):\n",
    "    if text_area.value.strip():\n",
    "        loaded_text['text'] = text_area.value.strip()\n",
    "        status.value = f\"‚úÖ Using pasted text ({len(loaded_text['text'])} chars)\"\n",
    "    else:\n",
    "        status.value = '‚ö†Ô∏è Paste some text first'\n",
    "\n",
    "load_btn.on_click(on_load_pdf)\n",
    "use_text_btn.on_click(on_use_text)\n",
    "\n",
    "ui = VBox([\n",
    "    HBox([Label('Upload:'), pdf_uploader]),\n",
    "    HBox([path_field, load_btn, use_text_btn]),\n",
    "    text_area,\n",
    "    status\n",
    "])\n",
    "ui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt and Examples (Editable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ce99541c944705bc4ddcd215699dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Textarea(value='You are a biomedical information extraction agent. Extract only facts that‚Ä¶"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load default system prompt and examples; allow editing\n",
    "from langextract_integration.schema_classes import BIOMEDICAL_SYSTEM_PROMPT, BiomedicExtractionClasses\n",
    "from ipywidgets import Accordion, Textarea\n",
    "\n",
    "extraction_classes = BiomedicExtractionClasses()\n",
    "\n",
    "prompt_area = Textarea(\n",
    "    value=BIOMEDICAL_SYSTEM_PROMPT.strip(),\n",
    "    description='System Prompt:',\n",
    "    layout=dict(width='100%', height='220px')\n",
    ")\n",
    "\n",
    "# Seed editable examples from PatientRecord few-shot\n",
    "seed_examples = extraction_classes.patient_record.few_shot_examples or []\n",
    "examples_area = Textarea(\n",
    "    value=json.dumps(seed_examples, indent=2),\n",
    "    description='Examples (JSON):',\n",
    "    layout=dict(width='100%', height='260px')\n",
    ")\n",
    "\n",
    "acc = Accordion(children=[prompt_area, examples_area])\n",
    "acc.set_title(0, 'System Prompt')\n",
    "acc.set_title(1, 'Few-shot Examples')\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e755452ea13c4f9da02f847e47cf2750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=2, description='Passes', max=3, min=1), IntSlider(value=4, description='Workers‚Ä¶"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Controls\n",
    "from ipywidgets import IntSlider, Checkbox, VBox\n",
    "\n",
    "passes_slider = IntSlider(description='Passes', min=1, max=3, value=2)\n",
    "workers_slider = IntSlider(description='Workers', min=1, max=8, value=4)\n",
    "segment_chk = Checkbox(description='Segment patients', value=True)\n",
    "visual_chk = Checkbox(description='Include visualization', value=True)\n",
    "\n",
    "VBox([passes_slider, workers_slider, segment_chk, visual_chk])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPO data file not found: data/ontologies/hpo/hp.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ready to extract\n"
     ]
    }
   ],
   "source": [
    "# Initialize engine\n",
    "results = None\n",
    "engine = LangExtractEngine(\n",
    "    model_id=MODEL_ID,\n",
    "    openrouter_api_key=os.getenv('OPENROUTER_API_KEY'),\n",
    "    use_local_model=USE_LOCAL_MODEL,\n",
    "    local_model_url=LOCAL_MODEL_URL\n",
    ")\n",
    "\n",
    "print('üöÄ Ready to extract')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d89a0f098ce4363a6a479d91f5151ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='primary', description='Run Extraction', style=ButtonStyle()), Output()))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run extraction\n",
    "from ipywidgets import Output, Button\n",
    "\n",
    "out = Output()\n",
    "run_btn = Button(description='Run Extraction', button_style='primary')\n",
    "\n",
    "def run_extraction(_):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        text = loaded_text.get('text') or ''\n",
    "        if not text.strip():\n",
    "            print('‚ö†Ô∏è No input text loaded. Load a PDF or paste text.')\n",
    "            return\n",
    "        try:\n",
    "            # Parse examples JSON\n",
    "            examples_override = None\n",
    "            if examples_area.value.strip():\n",
    "                try:\n",
    "                    examples_override = json.loads(examples_area.value)\n",
    "                except Exception as je:\n",
    "                    print('‚ö†Ô∏è Examples JSON invalid, ignoring override:', je)\n",
    "                    examples_override = None\n",
    "            print('üöÄ Running...')\n",
    "            res = engine.extract_from_text(\n",
    "                text=text,\n",
    "                extraction_passes=passes_slider.value,\n",
    "                max_workers=workers_slider.value,\n",
    "                segment_patients=segment_chk.value,\n",
    "                include_visualization=visual_chk.value,\n",
    "                prompt_description=prompt_area.value,\n",
    "                examples_override=examples_override,\n",
    "            )\n",
    "            global results\n",
    "            results = res\n",
    "            total = len(res.get('extractions') or res.get('original_extractions') or [])\n",
    "            print(f'‚úÖ Done. Extractions: {total}; Patients: {len(res.get(\"normalized_data\", []))}')\n",
    "        except Exception as e:\n",
    "            print('‚ùå Extraction failed:', e)\n",
    "\n",
    "run_btn.on_click(run_extraction)\n",
    "VBox([run_btn, out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results: Raw and Normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No results yet\n",
      "‚ùå No normalized data\n"
     ]
    }
   ],
   "source": [
    "# Raw\n",
    "if results:\n",
    "    extractions = results.get('extractions') or results.get('original_extractions') or []\n",
    "    print('üîç Raw extraction sample:')\n",
    "    for i, ex in enumerate(extractions[:3]):\n",
    "        print(f'\\nExtraction {i+1}:')\n",
    "        print(json.dumps(ex, indent=2, default=str))\n",
    "else:\n",
    "    print('‚ùå No results yet')\n",
    "\n",
    "# Normalized\n",
    "if results and 'normalized_data' in results:\n",
    "    df = pd.DataFrame(results['normalized_data'])\n",
    "    print('\\nüìã Normalized Patient Records:')\n",
    "    print('Rows:', len(df))\n",
    "    display(df.head(10))\n",
    "else:\n",
    "    df = None\n",
    "    print('‚ùå No normalized data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangExtract Integration ‚Äì All-in-One Demo\n",
    "\n",
    "This notebook demonstrates an end-to-end extraction workflow optimized for PDFs and free-form text:\n",
    "\n",
    "- Load env and route via OpenRouter (from `.env`)\n",
    "- Use project venv (prints Python executable)\n",
    "- Upload/select a PDF or paste text; parse via `src/processors/pdf_parser.py`\n",
    "- Edit the LangExtract system prompt and few-shot examples\n",
    "- Run extraction with `src/langextract_integration`\n",
    "- Review raw results, normalized table, and LangExtract visualizations\n",
    "- Save outputs (JSON, JSONL, HTML, CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded .env from: /Users/Mitya/Desktop/working/biomedicalmedical_text_agent/.env\n",
      "üß™ Python: /Users/Mitya/Desktop/working/biomedicalmedical_text_agent/venv/bin/python\n",
      "ü™∫ VIRTUAL_ENV: /Users/Mitya/Desktop/working/biomedicalmedical_text_agent/venv\n",
      "üîë OpenRouter API key detected and configured\n",
      "‚úÖ nbformat available\n"
     ]
    }
   ],
   "source": [
    "# Environment: load .env, configure OpenRouter, show venv\n",
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from repository root\n",
    "repo_root = os.path.abspath(os.path.join('..'))\n",
    "env_file = os.path.join(repo_root, '.env')\n",
    "if os.path.exists(env_file):\n",
    "    load_dotenv(env_file)\n",
    "    print(\"‚úÖ Loaded .env from:\", env_file)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è .env not found at:\", env_file)\n",
    "\n",
    "# Show interpreter and venv\n",
    "print(\"üß™ Python:\", sys.executable)\n",
    "print(\"ü™∫ VIRTUAL_ENV:\", os.environ.get('VIRTUAL_ENV', 'not set'))\n",
    "\n",
    "# Configure OpenRouter\n",
    "OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\n",
    "if OPENROUTER_API_KEY:\n",
    "    os.environ['OPENAI_BASE_URL'] = 'https://openrouter.ai/api/v1'\n",
    "    os.environ['OPENAI_API_KEY'] = OPENROUTER_API_KEY\n",
    "    os.environ['OPENROUTER_API_KEY'] = OPENROUTER_API_KEY\n",
    "    print(\"üîë OpenRouter API key detected and configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è OPENROUTER_API_KEY not set; cloud extraction will fail\")\n",
    "\n",
    "# Ensure nbformat for Plotly inline rendering\n",
    "try:\n",
    "    import nbformat  # noqa: F401\n",
    "    print(\"‚úÖ nbformat available\")\n",
    "except Exception:\n",
    "    import subprocess\n",
    "    print(\"‚¨áÔ∏è Installing nbformat for inline rendering...\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'nbformat>=4.2.0'])\n",
    "    import nbformat\n",
    "    print(\"‚úÖ nbformat installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports ready\n"
     ]
    }
   ],
   "source": [
    "# Imports and project modules\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Ensure src on path\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "\n",
    "# LangExtract integration\n",
    "from langextract_integration import (\n",
    "    LangExtractEngine,\n",
    "    BiomedicExtractionClasses,\n",
    "    BiomedicNormalizer,\n",
    "    ExtractionVisualizer,\n",
    ")\n",
    "\n",
    "# Processors\n",
    "from processors.pdf_parser import PDFParser\n",
    "\n",
    "print(\"‚úÖ Imports ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Model: gpt-4o-mini\n",
      "üñ•Ô∏è Local model enabled: False\n",
      "üåê Local URL: http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "# Config controls\n",
    "MODEL_ID = os.getenv('LANGEXTRACT_MODEL_ID', 'gpt-4o-mini')\n",
    "USE_LOCAL_MODEL = os.getenv('USE_LOCAL_MODEL', 'false').lower() in ('1','true','yes')\n",
    "LOCAL_MODEL_URL = os.getenv('LOCAL_MODEL_URL', 'http://localhost:11434')\n",
    "\n",
    "print('ü§ñ Model:', MODEL_ID)\n",
    "print('üñ•Ô∏è Local model enabled:', USE_LOCAL_MODEL)\n",
    "print('üåê Local URL:', LOCAL_MODEL_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# Prefer OpenAI-compatible id to force OpenRouter over Ollama inside LangExtract\n",
    "MODEL_ID = os.getenv(\"LANGEXTRACT_MODEL_ID\", \"gpt-4o-mini\")\n",
    "\n",
    "# Optional local (Ollama) configuration\n",
    "USE_LOCAL_MODEL = os.getenv(\"USE_LOCAL_MODEL\", \"false\").lower() in (\"1\", \"true\", \"yes\")\n",
    "LOCAL_MODEL_ID = os.getenv(\"LOCAL_MODEL_ID\", \"llama3\")\n",
    "LOCAL_MODEL_URL = os.getenv(\"LOCAL_MODEL_URL\", \"http://localhost:11434\")\n",
    "\n",
    "# Load API key from environment for safety (cloud route)\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if not USE_LOCAL_MODEL:\n",
    "    if not OPENROUTER_API_KEY:\n",
    "        print(\"‚ö†Ô∏è OPENROUTER_API_KEY is not set. Set it in your environment to run extraction.\")\n",
    "    else:\n",
    "        print(\"üîë API Key detected in environment\")\n",
    "        # Ensure LangExtract and OpenAI SDKs route via OpenRouter\n",
    "        os.environ[\"OPENAI_BASE_URL\"] = \"https://openrouter.ai/api/v1\"\n",
    "        os.environ[\"OPENAI_API_KEY\"] = OPENROUTER_API_KEY\n",
    "        os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
    "\n",
    "# Echo effective route\n",
    "if USE_LOCAL_MODEL:\n",
    "    print(f\"üñ•Ô∏è Using local model via Ollama: {LOCAL_MODEL_ID} @ {LOCAL_MODEL_URL}\")\n",
    "    EFFECTIVE_MODEL_ID = LOCAL_MODEL_ID\n",
    "else:\n",
    "    print(f\"‚òÅÔ∏è Using OpenRouter (OpenAI-compatible): {MODEL_ID}\")\n",
    "    EFFECTIVE_MODEL_ID = MODEL_ID\n",
    "\n",
    "print(f\"ü§ñ Effective model: {EFFECTIVE_MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input: Upload PDF or Paste Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e140b806b24a6d98fd705cd1f35e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Upload:'), FileUpload(value=(), accept='.pdf', description='Upload'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File input helpers\n",
    "from pathlib import Path\n",
    "from ipywidgets import VBox, HBox, Text, Textarea, FileUpload, Button, Label\n",
    "\n",
    "pdf_uploader = FileUpload(accept='.pdf', multiple=False)\n",
    "path_field = Text(value='../data/input/example.pdf', description='Path:')\n",
    "text_area = Textarea(value='', description='Text:', layout=dict(width='100%', height='200px'))\n",
    "status = Label(value='')\n",
    "\n",
    "load_btn = Button(description='Load PDF', button_style='primary')\n",
    "use_text_btn = Button(description='Use Text', button_style='success')\n",
    "\n",
    "loaded_text = {'text': ''}\n",
    "\n",
    "def on_load_pdf(_):\n",
    "    # Priority 1: file uploader\n",
    "    if pdf_uploader.value:\n",
    "        up_item = next(iter(pdf_uploader.value.values()))\n",
    "        tmp_path = Path('uploaded.pdf')\n",
    "        with open(tmp_path, 'wb') as f:\n",
    "            f.write(up_item['content'])\n",
    "        parser = PDFParser()\n",
    "        res = parser.process(str(tmp_path))\n",
    "        if res.success:\n",
    "            loaded_text['text'] = res.data.content\n",
    "            status.value = f\"‚úÖ Loaded from upload ({len(loaded_text['text'])} chars)\"\n",
    "        else:\n",
    "            status.value = f\"‚ùå PDF parsing failed: {res.error}\"\n",
    "        return\n",
    "    # Priority 2: path field\n",
    "    p = Path(path_field.value)\n",
    "    if p.exists() and p.suffix.lower() == '.pdf':\n",
    "        parser = PDFParser()\n",
    "        res = parser.process(str(p))\n",
    "        if res.success:\n",
    "            loaded_text['text'] = res.data.content\n",
    "            status.value = f\"‚úÖ Loaded from path ({len(loaded_text['text'])} chars)\"\n",
    "        else:\n",
    "            status.value = f\"‚ùå PDF parsing failed: {res.error}\"\n",
    "    else:\n",
    "        status.value = '‚ö†Ô∏è Provide a valid .pdf path or upload a file'\n",
    "\n",
    "def on_use_text(_):\n",
    "    if text_area.value.strip():\n",
    "        loaded_text['text'] = text_area.value.strip()\n",
    "        status.value = f\"‚úÖ Using pasted text ({len(loaded_text['text'])} chars)\"\n",
    "    else:\n",
    "        status.value = '‚ö†Ô∏è Paste some text first'\n",
    "\n",
    "load_btn.on_click(on_load_pdf)\n",
    "use_text_btn.on_click(on_use_text)\n",
    "\n",
    "ui = VBox([\n",
    "    HBox([Label('Upload:'), pdf_uploader]),\n",
    "    HBox([path_field, load_btn, use_text_btn]),\n",
    "    text_area,\n",
    "    status\n",
    "])\n",
    "ui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt and Examples (Editable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c55173fe0ce4bd2a8734701e727ae32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Textarea(value='You are a biomedical information extraction agent. Extract only facts that‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load default system prompt and examples; allow editing\n",
    "from langextract_integration.schema_classes import BIOMEDICAL_SYSTEM_PROMPT, BiomedicExtractionClasses\n",
    "from ipywidgets import Accordion, Textarea\n",
    "\n",
    "extraction_classes = BiomedicExtractionClasses()\n",
    "\n",
    "prompt_area = Textarea(\n",
    "    value=BIOMEDICAL_SYSTEM_PROMPT.strip(),\n",
    "    description='System Prompt:',\n",
    "    layout=dict(width='100%', height='220px')\n",
    ")\n",
    "\n",
    "# Seed editable examples from PatientRecord few-shot\n",
    "seed_examples = extraction_classes.patient_record.few_shot_examples or []\n",
    "examples_area = Textarea(\n",
    "    value=json.dumps(seed_examples, indent=2),\n",
    "    description='Examples (JSON):',\n",
    "    layout=dict(width='100%', height='260px')\n",
    ")\n",
    "\n",
    "acc = Accordion(children=[prompt_area, examples_area])\n",
    "acc.set_title(0, 'System Prompt')\n",
    "acc.set_title(1, 'Few-shot Examples')\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691b6587a7274324ad8af5cb7fdf091b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=2, description='Passes', max=3, min=1), IntSlider(value=4, description='Workers‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Controls\n",
    "from ipywidgets import IntSlider, Checkbox, VBox\n",
    "\n",
    "passes_slider = IntSlider(description='Passes', min=1, max=3, value=2)\n",
    "workers_slider = IntSlider(description='Workers', min=1, max=8, value=4)\n",
    "segment_chk = Checkbox(description='Segment patients', value=True)\n",
    "visual_chk = Checkbox(description='Include visualization', value=True)\n",
    "\n",
    "VBox([passes_slider, workers_slider, segment_chk, visual_chk])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPO data file not found: data/ontologies/hpo/hp.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ready to extract\n"
     ]
    }
   ],
   "source": [
    "# Initialize engine\n",
    "results = None\n",
    "engine = LangExtractEngine(\n",
    "    model_id=MODEL_ID,\n",
    "    openrouter_api_key=os.getenv('OPENROUTER_API_KEY'),\n",
    "    use_local_model=USE_LOCAL_MODEL,\n",
    "    local_model_url=LOCAL_MODEL_URL\n",
    ")\n",
    "\n",
    "print('üöÄ Ready to extract')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c52bb4afa364fe8afc53aba2f90c956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='primary', description='Run Extraction', style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run extraction\n",
    "from ipywidgets import Output, Button\n",
    "\n",
    "out = Output()\n",
    "run_btn = Button(description='Run Extraction', button_style='primary')\n",
    "\n",
    "def run_extraction(_):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        text = loaded_text.get('text') or ''\n",
    "        if not text.strip():\n",
    "            print('‚ö†Ô∏è No input text loaded. Load a PDF or paste text.')\n",
    "            return\n",
    "        try:\n",
    "            # Parse examples JSON\n",
    "            examples_override = None\n",
    "            if examples_area.value.strip():\n",
    "                try:\n",
    "                    examples_override = json.loads(examples_area.value)\n",
    "                except Exception as je:\n",
    "                    print('‚ö†Ô∏è Examples JSON invalid, ignoring override:', je)\n",
    "                    examples_override = None\n",
    "            print('üöÄ Running...')\n",
    "            res = engine.extract_from_text(\n",
    "                text=text,\n",
    "                extraction_passes=passes_slider.value,\n",
    "                max_workers=workers_slider.value,\n",
    "                segment_patients=segment_chk.value,\n",
    "                include_visualization=visual_chk.value,\n",
    "                prompt_description=prompt_area.value,\n",
    "                examples_override=examples_override,\n",
    "            )\n",
    "            global results\n",
    "            results = res\n",
    "            total = len(res.get('extractions') or res.get('original_extractions') or [])\n",
    "            print(f'‚úÖ Done. Extractions: {total}; Patients: {len(res.get(\"normalized_data\", []))}')\n",
    "        except Exception as e:\n",
    "            print('‚ùå Extraction failed:', e)\n",
    "\n",
    "run_btn.on_click(run_extraction)\n",
    "VBox([run_btn, out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results: Raw and Normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No results yet\n",
      "‚ùå No normalized data\n"
     ]
    }
   ],
   "source": [
    "# Raw\n",
    "if results:\n",
    "    extractions = results.get('extractions') or results.get('original_extractions') or []\n",
    "    print('üîç Raw extraction sample:')\n",
    "    for i, ex in enumerate(extractions[:3]):\n",
    "        print(f'\\nExtraction {i+1}:')\n",
    "        print(json.dumps(ex, indent=2, default=str))\n",
    "else:\n",
    "    print('‚ùå No results yet')\n",
    "\n",
    "# Normalized\n",
    "if results and 'normalized_data' in results:\n",
    "    df = pd.DataFrame(results['normalized_data'])\n",
    "    print('\\nüìã Normalized Patient Records:')\n",
    "    print('Rows:', len(df))\n",
    "    display(df.head(10))\n",
    "else:\n",
    "    df = None\n",
    "    print('‚ùå No normalized data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è No LangExtract HTML in results or visualization disabled\n",
      "‚ùå No normalized data for charts\n"
     ]
    }
   ],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Built-in LangExtract HTML (if available)\n",
    "if results and results.get('visualization_html'):\n",
    "    html_content = results['visualization_html']\n",
    "    with open('langextract_visualization.html', 'w') as f:\n",
    "        f.write(html_content)\n",
    "    print(\"üé® Saved LangExtract visualization ‚Üí langextract_visualization.html\")\n",
    "    display(HTML(html_content[:800] + ('...' if len(html_content) > 800 else '')))\n",
    "else:\n",
    "    print('‚ÑπÔ∏è No LangExtract HTML in results or visualization disabled')\n",
    "\n",
    "# Fallback overview dashboard\n",
    "if results and results.get('normalized_data'):\n",
    "    viz = ExtractionVisualizer()\n",
    "    fig = viz.create_overview_dashboard(results)\n",
    "    fig.show()\n",
    "else:\n",
    "    print('‚ùå No normalized data for charts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No results to save\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "if results:\n",
    "    out_dir = './output'\n",
    "    prefix = 'langextract_demo'\n",
    "    saved = engine.save_results(results, out_dir, prefix)\n",
    "    print('üíæ Saved:')\n",
    "    for k, v in saved.items():\n",
    "        print(' -', k.upper(), ':', v)\n",
    "else:\n",
    "    print('‚ùå No results to save')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è No LangExtract HTML in results or visualization disabled\n",
      "‚ùå No normalized data for charts\n"
     ]
    }
   ],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Built-in LangExtract HTML (if available)\n",
    "if results and results.get('visualization_html'):\n",
    "    html_content = results['visualization_html']\n",
    "    with open('langextract_visualization.html', 'w') as f:\n",
    "        f.write(html_content)\n",
    "    print(\"üé® Saved LangExtract visualization ‚Üí langextract_visualization.html\")\n",
    "    display(HTML(html_content[:800] + ('...' if len(html_content) > 800 else '')))\n",
    "else:\n",
    "    print('‚ÑπÔ∏è No LangExtract HTML in results or visualization disabled')\n",
    "\n",
    "# Fallback overview dashboard\n",
    "if results and results.get('normalized_data'):\n",
    "    viz = ExtractionVisualizer()\n",
    "    fig = viz.create_overview_dashboard(results)\n",
    "    fig.show()\n",
    "else:\n",
    "    print('‚ùå No normalized data for charts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No results to save\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "if results:\n",
    "    out_dir = './output'\n",
    "    prefix = 'langextract_demo'\n",
    "    saved = engine.save_results(results, out_dir, prefix)\n",
    "    print('üíæ Saved:')\n",
    "    for k, v in saved.items():\n",
    "        print(' -', k.upper(), ':', v)\n",
    "else:\n",
    "    print('‚ùå No results to save')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
