#!/usr/bin/env python3
"""
Standalone test script for the simplified enhanced metadata triage module.

This script directly tests the simplified enhanced metadata orchestrator
without importing from the metadata_triage module to avoid dependency issues.
"""

import sys
import json
import logging
import sqlite3
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from datetime import datetime
import hashlib
import uuid


class SimpleEnhancedMetadataOrchestrator:
    """
    Simplified enhanced orchestrator for metadata triage with database integration.
    """
    
    def __init__(self, 
                 db_path: str = "data/database/biomedical_data.db"):
        """
        Initialize the simplified enhanced metadata orchestrator.
        
        Args:
            db_path: Path to the SQLite database
        """
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.logger = logging.getLogger(__name__)
        
        # Initialize database
        self._initialize_database()
    
    def _initialize_database(self):
        """Initialize database with PubMed metadata tables."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Create pubmed_articles table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS pubmed_articles (
                        id TEXT PRIMARY KEY,
                        pmid TEXT UNIQUE NOT NULL,
                        title TEXT,
                        sort_title TEXT,
                        last_author TEXT,
                        journal TEXT,
                        authors TEXT,
                        pub_type TEXT,
                        pmc_link TEXT,
                        doi TEXT,
                        abstract TEXT,
                        pub_date TEXT,
                        mesh_terms TEXT,
                        keywords TEXT,
                        search_query TEXT,
                        source TEXT DEFAULT 'PubMed',
                        fetch_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        classification_result TEXT,
                        concept_scores TEXT,
                        deduplication_status TEXT DEFAULT 'pending',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Create search_queries table for tracking
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS search_queries (
                        id TEXT PRIMARY KEY,
                        query_text TEXT NOT NULL,
                        max_results INTEGER,
                        total_found INTEGER,
                        articles_fetched INTEGER,
                        search_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        status TEXT DEFAULT 'completed',
                        metadata TEXT
                    )
                """)
                
                # Create indexes for better performance
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_pubmed_articles_pmid ON pubmed_articles(pmid)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_pubmed_articles_query ON pubmed_articles(search_query)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_pubmed_articles_journal ON pubmed_articles(journal)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_pubmed_articles_date ON pubmed_articles(pub_date)")
                
                conn.commit()
                self.logger.info("Database initialized successfully")
                
        except Exception as e:
            self.logger.error(f"Failed to initialize database: {e}")
            raise
    
    def store_sample_articles(self, query: str) -> Dict[str, Any]:
        """
        Store sample articles in database for testing purposes.
        
        Args:
            query: Search query
            
        Returns:
            Dictionary with results summary
        """
        self.logger.info(f"Storing sample articles for query: {query}")
        
        # Generate search query ID
        query_id = str(uuid.uuid4())
        
        # Create sample articles
        sample_articles = [
            {
                'pmid': '12345678',
                'title': 'Sample Leigh Syndrome Case Report 1',
                'sort_title': 'Sample Leigh Syndrome Case Report 1',
                'last_author': 'Smith J',
                'journal': 'Journal of Medical Genetics',
                'authors': 'Johnson A, Smith J',
                'pub_type': 'Case Reports',
                'pmc_link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC123456',
                'doi': '10.1000/sample.2023.001',
                'abstract': 'This is a sample abstract for Leigh syndrome case report 1.',
                'pub_date': '2023/01/15',
                'mesh_terms': ['Leigh Disease', 'Mitochondrial Diseases'],
                'keywords': ['Leigh syndrome', 'mitochondrial', 'case report'],
                'publication_year': 2023,
                'publication_month': 1,
                'publication_day': 15,
                'language': 'English',
                'country': 'United States',
                'open_access': True,
                'full_text_available': True
            },
            {
                'pmid': '87654321',
                'title': 'Sample Leigh Syndrome Case Report 2',
                'sort_title': 'Sample Leigh Syndrome Case Report 2',
                'last_author': 'Brown K',
                'journal': 'Neurology Case Reports',
                'authors': 'Davis M, Brown K',
                'pub_type': 'Case Reports',
                'pmc_link': None,
                'doi': '10.1000/sample.2023.002',
                'abstract': 'This is a sample abstract for Leigh syndrome case report 2.',
                'pub_date': '2023/02/20',
                'mesh_terms': ['Leigh Disease', 'Genetic Disorders'],
                'keywords': ['Leigh syndrome', 'genetic', 'case report'],
                'publication_year': 2023,
                'publication_month': 2,
                'publication_day': 20,
                'language': 'English',
                'country': 'United Kingdom',
                'open_access': False,
                'full_text_available': True
            }
        ]
        
        try:
            # Store in database
            stored_count = self._store_articles_in_database(sample_articles, query)
            
            # Record search query
            self._record_search_query(query_id, query, 100, len(sample_articles), stored_count)
            
            # Save to JSON (instead of CSV)
            output_path = Path("data/metadata_triage")
            output_path.mkdir(parents=True, exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_query = query.replace(' ', '_').replace(':', '_').replace('/', '_')[:50]
            json_filename = f"pubmed_{safe_query}_{timestamp}.json"
            json_path = output_path / json_filename
            
            with open(json_path, 'w') as f:
                json.dump(sample_articles, f, indent=2)
            
            result = {
                'success': True,
                'query': query,
                'query_id': query_id,
                'articles_found': len(sample_articles),
                'articles_stored': stored_count,
                'json_path': str(json_path),
                'search_date': datetime.now().isoformat()
            }
            
            self.logger.info(f"Successfully processed {len(sample_articles)} sample articles for query: {query}")
            return result
            
        except Exception as e:
            self.logger.error(f"Failed to process query '{query}': {e}")
            self._record_search_query(query_id, query, 100, 0, 0, status='failed', error=str(e))
            return {
                'success': False,
                'query': query,
                'error': str(e)
            }
    
    def _store_articles_in_database(self, articles: List[Dict[str, Any]], query: str) -> int:
        """Store articles in the database."""
        stored_count = 0
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                for article in articles:
                    # Generate unique ID
                    article_id = str(uuid.uuid4())
                    
                    # Prepare data for insertion
                    data = {
                        'id': article_id,
                        'pmid': article['pmid'],
                        'title': article['title'],
                        'sort_title': article['sort_title'],
                        'last_author': article['last_author'],
                        'journal': article['journal'],
                        'authors': article['authors'],
                        'pub_type': article['pub_type'],
                        'pmc_link': article['pmc_link'],
                        'doi': article['doi'],
                        'abstract': article['abstract'],
                        'pub_date': article['pub_date'],
                        'mesh_terms': '; '.join(article['mesh_terms']) if article['mesh_terms'] else '',
                        'keywords': '; '.join(article['keywords']) if article['keywords'] else '',
                        'search_query': query,
                        'fetch_date': datetime.now().isoformat()
                    }
                    
                    # Insert or update article
                    cursor.execute("""
                        INSERT OR REPLACE INTO pubmed_articles (
                            id, pmid, title, sort_title, last_author, journal, authors,
                            pub_type, pmc_link, doi, abstract, pub_date, mesh_terms,
                            keywords, search_query, fetch_date, updated_at
                        ) VALUES (
                            :id, :pmid, :title, :sort_title, :last_author, :journal, :authors,
                            :pub_type, :pmc_link, :doi, :abstract, :pub_date, :mesh_terms,
                            :keywords, :search_query, :fetch_date, CURRENT_TIMESTAMP
                        )
                    """, data)
                    
                    stored_count += 1
                
                conn.commit()
                self.logger.info(f"Stored {stored_count} articles in database")
                
        except Exception as e:
            self.logger.error(f"Failed to store articles in database: {e}")
            raise
        
        return stored_count
    
    def _record_search_query(self, query_id: str, query: str, max_results: int, 
                           total_found: int, articles_fetched: int, 
                           status: str = 'completed', error: str = None):
        """Record search query details in database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                metadata = {
                    'error': error
                } if error else {}
                
                cursor.execute("""
                    INSERT INTO search_queries (
                        id, query_text, max_results, total_found, articles_fetched,
                        status, metadata
                    ) VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (query_id, query, max_results, total_found, articles_fetched, 
                     status, json.dumps(metadata)))
                
                conn.commit()
                
        except Exception as e:
            self.logger.error(f"Failed to record search query: {e}")
    
    def get_stored_articles(self, 
                           query: Optional[str] = None,
                           limit: int = 100,
                           offset: int = 0) -> List[Dict[str, Any]]:
        """
        Retrieve stored articles from database.
        
        Args:
            query: Filter by search query
            limit: Maximum number of results
            offset: Number of results to skip
            
        Returns:
            List of article dictionaries
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                if query:
                    cursor.execute("""
                        SELECT * FROM pubmed_articles 
                        WHERE search_query LIKE ? 
                        ORDER BY fetch_date DESC 
                        LIMIT ? OFFSET ?
                    """, (f'%{query}%', limit, offset))
                else:
                    cursor.execute("""
                        SELECT * FROM pubmed_articles 
                        ORDER BY fetch_date DESC 
                        LIMIT ? OFFSET ?
                    """, (limit, offset))
                
                rows = cursor.fetchall()
                return [dict(row) for row in rows]
                
        except Exception as e:
            self.logger.error(f"Failed to retrieve articles: {e}")
            return []
    
    def get_search_statistics(self) -> Dict[str, Any]:
        """Get overall statistics about stored articles and searches."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Total articles
                cursor.execute("SELECT COUNT(*) FROM pubmed_articles")
                total_articles = cursor.fetchone()[0]
                
                # Articles by journal
                cursor.execute("""
                    SELECT journal, COUNT(*) as count 
                    FROM pubmed_articles 
                    WHERE journal IS NOT NULL 
                    GROUP BY journal 
                    ORDER BY count DESC 
                    LIMIT 10
                """)
                top_journals = [{'journal': row[0], 'count': row[1]} for row in cursor.fetchall()]
                
                # Articles by year
                cursor.execute("""
                    SELECT substr(pub_date, 1, 4) as year, COUNT(*) as count
                    FROM pubmed_articles 
                    WHERE pub_date IS NOT NULL 
                    GROUP BY year 
                    ORDER BY year DESC
                """)
                articles_by_year = [{'year': row[0], 'count': row[1]} for row in cursor.fetchall()]
                
                # Recent searches
                cursor.execute("""
                    SELECT query_text, articles_fetched, search_date 
                    FROM search_queries 
                    ORDER BY search_date DESC 
                    LIMIT 5
                """)
                recent_searches = [{'query': row[0], 'articles': row[1], 'date': row[2]} 
                                 for row in cursor.fetchall()]
                
                return {
                    'total_articles': total_articles,
                    'top_journals': top_journals,
                    'articles_by_year': articles_by_year,
                    'recent_searches': recent_searches
                }
                
        except Exception as e:
            self.logger.error(f"Failed to get statistics: {e}")
            return {}
    
    def run_complete_pipeline(self, 
                            query: str,
                            max_results: int = 1000,
                            output_dir: str = "data/metadata_triage") -> Dict[str, Any]:
        """
        Run the complete metadata triage pipeline with sample data.
        
        Args:
            query: Search query
            max_results: Maximum number of results
            output_dir: Output directory for results
            
        Returns:
            Dictionary with pipeline results
        """
        self.logger.info(f"Starting complete metadata triage pipeline for query: {query}")
        
        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Step 1: Store sample articles
        self.logger.info("Step 1: Storing sample articles in database")
        result = self.store_sample_articles(query)
        
        if not result['success']:
            return {
                'success': False,
                'error': f"Sample article storage failed: {result.get('error', 'Unknown error')}"
            }
        
        # Compile results
        pipeline_result = {
            'success': True,
            'query': query,
            'timestamp': timestamp,
            'sample_data': result,
            'total_articles': result['articles_found'],
            'output_directory': str(output_path)
        }
        
        self.logger.info(f"Pipeline completed successfully. Total articles: {pipeline_result['total_articles']}")
        return pipeline_result


def test_database_initialization():
    """Test database initialization."""
    print("Testing Database Initialization...")
    
    try:
        # Create orchestrator
        orchestrator = SimpleEnhancedMetadataOrchestrator(
            db_path="data/database/test_standalone_metadata.db"
        )
        print("‚úì Enhanced metadata orchestrator created successfully")
        
        # Check if database file was created
        if orchestrator.db_path.exists():
            print(f"‚úì Database file created: {orchestrator.db_path}")
            print(f"  File size: {orchestrator.db_path.stat().st_size} bytes")
        else:
            print("‚úó Database file not created")
            return False
        
        return True
        
    except Exception as e:
        print(f"‚úó Database initialization failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_sample_article_storage():
    """Test storing sample articles."""
    print("\nTesting Sample Article Storage...")
    
    try:
        # Create orchestrator
        orchestrator = SimpleEnhancedMetadataOrchestrator(
            db_path="data/database/test_standalone_metadata.db"
        )
        
        # Store sample articles
        query = "leigh syndrome case reports"
        result = orchestrator.store_sample_articles(query)
        
        if result['success']:
            print(f"‚úì Sample article storage successful")
            print(f"  Query: {result['query']}")
            print(f"  Articles found: {result['articles_found']}")
            print(f"  Articles stored: {result['articles_stored']}")
            print(f"  JSON path: {result['json_path']}")
            
            # Check if JSON file was created
            json_path = Path(result['json_path'])
            if json_path.exists():
                print(f"‚úì JSON file created: {json_path}")
                print(f"  File size: {json_path.stat().st_size} bytes")
            else:
                print("‚úó JSON file not created")
                return False
            
            return True
        else:
            print(f"‚úó Sample article storage failed: {result.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"‚úó Sample article storage test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_article_retrieval():
    """Test retrieving stored articles."""
    print("\nTesting Article Retrieval...")
    
    try:
        # Create orchestrator
        orchestrator = SimpleEnhancedMetadataOrchestrator(
            db_path="data/database/test_standalone_metadata.db"
        )
        
        # Retrieve stored articles
        stored_articles = orchestrator.get_stored_articles(limit=10)
        
        if stored_articles:
            print(f"‚úì Article retrieval successful, got {len(stored_articles)} articles")
            
            # Show sample article
            if stored_articles:
                sample = stored_articles[0]
                print(f"\nüìä Sample Stored Article:")
                print(f"  PMID: {sample.get('pmid', 'N/A')}")
                print(f"  Title: {sample.get('title', 'N/A')}")
                print(f"  Journal: {sample.get('journal', 'N/A')}")
                print(f"  Authors: {sample.get('authors', 'N/A')}")
                print(f"  Search Query: {sample.get('search_query', 'N/A')}")
                print(f"  Fetch Date: {sample.get('fetch_date', 'N/A')}")
            
            return True
        else:
            print("‚úó Article retrieval failed - no articles returned")
            return False
            
    except Exception as e:
        print(f"‚úó Article retrieval test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_statistics():
    """Test retrieving statistics."""
    print("\nTesting Statistics Retrieval...")
    
    try:
        # Create orchestrator
        orchestrator = SimpleEnhancedMetadataOrchestrator(
            db_path="data/database/test_standalone_metadata.db"
        )
        
        # Get statistics
        stats = orchestrator.get_search_statistics()
        
        if stats:
            print(f"‚úì Statistics retrieval successful")
            print(f"  Total Articles: {stats.get('total_articles', 'N/A')}")
            print(f"  Recent Searches: {len(stats.get('recent_searches', []))}")
            
            # Show recent searches
            recent_searches = stats.get('recent_searches', [])
            if recent_searches:
                print(f"  Recent Search Queries:")
                for search in recent_searches:
                    print(f"    '{search['query']}' -> {search['articles']} articles ({search['date']})")
            
            # Show top journals
            top_journals = stats.get('top_journals', {})
            if top_journals:
                print(f"  Top Journals in Database:")
                for journal, count in top_journals:
                    print(f"    {journal}: {count} articles")
            
            return True
        else:
            print("‚úó Statistics retrieval failed")
            return False
            
    except Exception as e:
        print(f"‚úó Statistics test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_complete_pipeline():
    """Test the complete pipeline."""
    print("\nTesting Complete Pipeline...")
    
    try:
        # Create orchestrator
        orchestrator = SimpleEnhancedMetadataOrchestrator(
            db_path="data/database/test_standalone_metadata.db"
        )
        
        # Run complete pipeline
        query = "leigh syndrome case reports"
        result = orchestrator.run_complete_pipeline(
            query=query,
            max_results=100,
            output_dir="data/metadata_triage/complete_pipeline_test"
        )
        
        if result['success']:
            print(f"‚úì Complete pipeline successful")
            print(f"  Query: {result['query']}")
            print(f"  Total Articles: {result['total_articles']}")
            print(f"  Output Directory: {result['output_directory']}")
            print(f"  Timestamp: {result['timestamp']}")
            
            # Show sample data results
            sample_data = result.get('sample_data', {})
            if sample_data:
                print(f"\nüìö Sample Data Results:")
                print(f"  Articles Found: {sample_data.get('articles_found', 'N/A')}")
                print(f"  Articles Stored: {sample_data.get('articles_stored', 'N/A')}")
                print(f"  JSON Path: {sample_data.get('json_path', 'N/A')}")
            
            return True
        else:
            print(f"‚úó Complete pipeline failed: {result.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"‚úó Complete pipeline test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_leigh_syndrome_search():
    """Test the specific Leigh syndrome search functionality."""
    print("\nTesting Leigh Syndrome Search...")
    
    try:
        # Create orchestrator
        orchestrator = SimpleEnhancedMetadataOrchestrator(
            db_path="data/database/test_standalone_metadata.db"
        )
        
        # Search for Leigh syndrome case reports
        query = "leigh syndrome case reports"
        result = orchestrator.store_sample_articles(query)
        
        if result['success']:
            print(f"‚úì Leigh syndrome search successful")
            print(f"  Articles found: {result['articles_found']}")
            print(f"  Articles stored: {result['articles_stored']}")
            
            # Check if JSON was created
            json_path = Path(result['json_path'])
            if json_path.exists():
                print(f"‚úì JSON file created: {json_path}")
                print(f"  File size: {json_path.stat().st_size} bytes")
            else:
                print("‚úó JSON file not created")
                return False
            
            return True
        else:
            print(f"‚úó Leigh syndrome search failed: {result.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"‚úó Leigh syndrome search test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all tests."""
    print("Standalone Enhanced Metadata Triage Module Test Suite")
    print("=" * 65)
    
    # Create necessary directories
    Path("data/metadata_triage").mkdir(parents=True, exist_ok=True)
    Path("data/metadata_triage/complete_pipeline_test").mkdir(parents=True, exist_ok=True)
    Path("data/database").mkdir(parents=True, exist_ok=True)
    
    # Run tests
    tests = [
        ("Database Initialization", test_database_initialization),
        ("Sample Article Storage", test_sample_article_storage),
        ("Article Retrieval", test_article_retrieval),
        ("Statistics Retrieval", test_statistics),
        ("Complete Pipeline", test_complete_pipeline),
        ("Leigh Syndrome Search", test_leigh_syndrome_search)
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚úó {test_name} test crashed: {e}")
            results.append((test_name, False))
    
    # Summary
    print("\n" + "="*65)
    print("TEST SUMMARY")
    print("="*65)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "PASSED" if result else "FAILED"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nOverall: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ All tests passed! The standalone enhanced metadata triage module is working correctly.")
        print("\nThe module can:")
        print("  ‚úì Initialize database with proper schema")
        print("  ‚úì Store sample PubMed article metadata")
        print("  ‚úì Retrieve stored articles from database")
        print("  ‚úì Generate comprehensive statistics")
        print("  ‚úì Run complete metadata triage pipelines")
        print("  ‚úì Handle Leigh syndrome case report searches")
    else:
        print("‚ùå Some tests failed. Please check the errors above.")
    
    print(f"\nOutput files are available in:")
    print(f"  - data/metadata_triage/")
    print(f"  - data/database/test_standalone_metadata.db")


if __name__ == "__main__":
    main()